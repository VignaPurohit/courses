---
title: "Mastering GDAL Tools (Full Course Material)"
subtitle: "Satellite and aerial image processing using GDAL tools"
author: "Ujaval Gandhi"
fontsize: 12pt
output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: 3
    highlight: pygments
    includes:
      after_body: disqus.html
  # pdf_document:
  #   toc: yes
  #   toc_depth: 3
  # word_document:
  #   toc: yes
  #   toc_depth: '3'
header-includes:
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \renewcommand{\footrulewidth}{0.4pt}
- \fancyhead[LE,RO]{\thepage}
- \geometry{left=1in,top=0.75in,bottom=0.75in}
- \fancyfoot[CE,CO]{{\includegraphics[height=0.5cm]{images/cc-by-nc.png}} Ujaval Gandhi http://www.spatialthoughts.com}
classoption: a4paper
---

\newpage

***

```{r echo=FALSE, fig.align='center', out.width='250pt'}
knitr::include_graphics('images/spatial_thoughts_logo.png')
```

***

\newpage

# Introduction 

[GDAL](https://gdal.org/)  is an open-source library for raster and vector geospatial data formats. The library comes with a vast collection of utility programs that can perform many geoprocessing tasks. This class introduces GDAL utilities with example workflows for processing satellite and aerial imagery.

# Get the Data Package

The code examples in this class use a variety of datasets. All the required datasets are supplied to you in the ``gdal_tools.zip`` file. Unzip this file to the `Downloads` directory. All commands below assume the data is available in the ``<home folder>/Downloads/gdal_tools/`` directory.

*Not enrolled in our instructor-led class but want to work through the material on your own?* [Get free access to the data package](https://docs.google.com/forms/d/e/1FAIpQLScfS6sICXfbAfPr2MOAkfAIbpj8G6v3FR_YtMRGOoKrDnDBtw/viewform){target="_blank"}

# Installation

The preferred method for installing the GDAL Tools is via Anaconda. Follow these steps to install Anaconda and the GDAL library.

[Download the Anaconda Installer](https://www.anaconda.com/products/individual) for Python 3.7 (or a higher version) for your operating system. Once downloaded, double click the installer and install it into the default suggested directory.

*Note: If your username has spaces, or non-English characters, it causes problems. In that case, you can install it to a path such as  `C:\anaconda`.*

```{r echo=FALSE, fig.align='center', out.width='75%'}
knitr::include_graphics('images/gdal/conda.png')
```

## Windows

Once Anaconda installed, search for *Anaconda Prompt* in the Start Menu and launch a new window.

1. Create a new environment named `gdal`. When prompted to confirm, type `y` and press *Enter*.

```
conda create --name gdal
```
> Note: You can use the shortcut *Shift + Insert* to paste commands in Anaconda Prompt.

```{r echo=FALSE, fig.align='center', out.width='75%'}
knitr::include_graphics('images/gdal/condawin1.png')
```

2. Activate the environment and install the `gdal` package. When prompted to confirm, type `y` and press *Enter*.

```
conda activate gdal
conda install -c conda-forge gdal
```


```{r echo=FALSE, fig.align='center', out.width='75%'}
knitr::include_graphics('images/gdal/condawin2.png')
```

3. Once the installation finishes, verify if you are able to run the GDAL tools. Type the following command and check if a version number is printed.

```
gdalinfo --version
```

> The version number displayed for you may be slightly different. As long as you do not get a `command not found` error, you should be set for the class.


```{r echo=FALSE, fig.align='center', out.width='75%'}
knitr::include_graphics('images/gdal/condawin3.png')
```

## Mac/Linux

Once Anaconda is installed, launch a *Terminal* window.

1. Create a new environment named `gdal`. When prompted to confirm, type `y` and press *Enter*.

```
conda create --name gdal
```

```{r echo=FALSE, fig.align='center', out.width='75%'}
knitr::include_graphics('images/gdal/condamac1.png')
```

2. Activate the environment and install the `gdal` package. When prompted to confirm, type `y` and press *Enter*.

```
conda activate gdal
conda install -c conda-forge gdal
```

```{r echo=FALSE, fig.align='center', out.width='75%'}
knitr::include_graphics('images/gdal/condamac2.png')
```

3. Once the installation finishes, verify if you are able to run the GDAL tools. Type the following command and check if a version number is printed.

```
gdalinfo --version
```

> The version number displayed for you may be slightly different. As long as you do not get a `command not found` error, you should be set for the class.

```{r echo=FALSE, fig.align='center', out.width='75%'}
knitr::include_graphics('images/gdal/condamac3.png')
```

# Getting Familiar with the Command Prompt

All the commands in the exercises below are expected to be run from the *Anaconda Prompt* on Windows or a *Terminal* on Mac/Linux. We will now cover basic terminal commands that will help you get comfortable with the environment

### Windows


|   **Command**    | **Description**                     | **Example**     |
|:-----------------|:------------------------------------|:---------------------|
| `cd`             | Change directory                    | `cd Downloads\gdal-tools` |
| `cd ..`          | Change to the parent directory      | `cd ..` |
| `dir`            | List files in the current directory | `dir` |
| `del`            | Delete a file                       | `del test.txt` |
| `rmdir`          | Delete a directory                  | `rmdir /s test` |
| `type`           | Print the contents of a file        | `type test.txt` |
| `> output.txt`   | Redirect the output to a file       | `dir /b *.csv > output.txt` |
| `cls`            | Clear screen                        | `cls` |


### Mac/Linux

|   **Command**    | **Description**                     | **Example**     |
|:-----------------|:------------------------------------|:---------------------|
| `cd`             | Change directory                    | `cd Downloads/gdal-tools` |
| `cd ..`          | Change to the parent directory      | `cd ..` |
| `ls`             | List files in the current directory | `ls` |
| `rm `            | Delete a file                       | `rm test.txt` |
| `rm -R`          | Delete a directory                  | `rm -R test` |
| `cat`            | Print the contents of a file        | `cat test.txt` |
| `> output.txt`   | Redirect the output to a file       | `ls *.csv > output.txt` |
| `clear`          | Clear screen                        | `clear` |


# GDAL Tools

## Basic Raster Processing

We will start learning the basic GDAL commands by processsing elevation rasters from SRTM. In the *Command Prompt* window, use the `cd` command to change to the `srtm` directory which 4 individual SRTM tiles around the Mt. Everest region.

```
cd srtm
```

Use the `gdalinfo` command to check the information about a single image. 
```
gdalinfo N27E086.hgt
```

```{r echo=FALSE, fig.align='center', out.width='75%'}
knitr::include_graphics('images/gdal/gdalinfo1.png')
```

A useful parameter is `-stats` which computes and displays image statistics. Run it on the raster to get some statistics of pixel values in the image.
```
gdalinfo -stats N27E086.hgt
```

```{r echo=FALSE, fig.align='center', out.width='75%'}
knitr::include_graphics('images/gdal/gdalinfo2.png')
```

### Merging Tiles

We will now merge the 4 neighboring SRTM tiles into 1 raster so we can work with them together. GDAL provides a useful format called [Virtual Raster](https://gdal.org/drivers/raster/vrt.html) that allows us to create a *Virtual* file with `.vrt` extension that is a pointer to multiple source files. A `.vrt` file is just a text file, so it doesn't consume any disk space but allows us to run any GDAL command as if it was a raster file. 

First we need to create a text file containing all the files we want to merge. We can use the `dir` command on Windows prompt list the files matching the pattern `*.hgt` and redirect the output to a file. Here the `/b` option runs the command in the *Bare* mode which excludes all info except file names. 

**Windows**
```
dir /b *.hgt > filelist.txt
```

On Mac/Linux systems, the same came be achieved using the `ls` command.

**Mac/Linux**
```
ls *.hgt > filelist.txt
```

Once the command finishes, verify that the `filelist.txt` has the names of the source tiles.

```{r echo=FALSE, fig.align='center', out.width='50%'}
knitr::include_graphics('images/gdal/merging1.png')
```

We can now use the `gdalbuildvrt` command to create a virtual raster from the source files in the `filelist.txt`.

```
gdalbuildvrt -input_file_list filelist.txt merged.vrt
```

```{r echo=FALSE, fig.align='center', out.width='100%'}
knitr::include_graphics('images/gdal/merging2.png')
```

> Note: We could have done this operation in a  single step using the command `gdalbuildvrt merged.vrt *.hgt`. However, some versions of GDAL on Windows do not expand the `*` wildcard correctly and the command results in an error. It is recommended to use a filelist instead of wildcards with GDAL commands on Windows to avoid unexpeted results.[[reference](https://github.com/OSGeo/gdal/issues/1749)]

### Exercise 1

Can you find out what is the highest elevation value in the merged raster? Since these rasters are around the Mt.Everest region, the *MAXIMUM* value will be the elevation of the summit.


```{r echo=FALSE, fig.align='center', out.width='75%'}
knitr::include_graphics('images/gdal/exercise1.png')
```

### Converting Formats

Let's conver the *Virtual Raster* to a GeoTIFF file. `gdal_translate` program allows us to convert between any of the hundreds of data formats supported by GDAL. The format is automatically guessed from the file extension. Alternatively, you can also specify it using the `-of` option with the [short name of the format](https://gdal.org/drivers/raster/index.html) such a **GTiff**.
```
gdal_translate -of GTiff merged.vrt merged.tif
```

```{r echo=FALSE, fig.align='center', out.width='75%'}
knitr::include_graphics('images/gdal/compression1.png')
```

### Compressing Output

The default output GeoTIFF file is uncompressed - meaning each pixel's value is stored on the disk without any further processing. For large rasters, this can consume a lot of disk space. A smarter approach is to use a lossless compression algorithm to reduce the size of the raster while maintaining full fidelity of the original data. GDAL supports many compression algorithm out-of-the-box and can be specified with GDAL commands using the `-co` option. The most popular loss-less compression algorithms are **DEFLATE**, **LZW** and **PACKBITS**. We can try the `DEFLATE` algorithm on our dataset.

```
gdal_translate -of GTiff merged.vrt merged.tif -co COMPRESS=DEFLATE
```

```{r echo=FALSE, fig.align='center', out.width='75%'}
knitr::include_graphics('images/gdal/compression2.png')
```


The uncompressed filesize was **100+ MB**. After applying the  *DEFLATE* compression, the file size reduced to **72MB**. We can further reduce the file size by specifying additional options. The `PREDICTOR` option helps compress data better when the neighboring values are correlated. For elevation data, this is definitely the case. The `TILED` option will compress the data in blocks rather than line-by-line.

```
gdal_translate -of GTiff merged.vrt merged.tif -co COMPRESS=DEFLATE -co TILED=YES -co PREDICTOR=2
```

```{r echo=FALSE, fig.align='center', out.width='75%'}
knitr::include_graphics('images/gdal/compression3.png')
```

The resulting file now comes out much smaller at **39MB**. Check this article [GeoTIFF compression and optimization with GDAL](https://kokoalberti.com/articles/geotiff-compression-optimization-guide/) to learn more about various options and compression algorithms. 

### Setting NoData Values

The output from `gdalinfo` command shows that the original data has a *NoData* Value set to `-32768`. We can set a new *NoData* value. The `-a_nodata` option allows us to specify a new value.

```
gdal_translate -of GTiff merged.vrt merged.tif -co COMPRESS=DEFLATE -co TILED=YES -co PREDICTOR=2 -a_nodata -9999
```

After running the command, you can verify the results using the `gdalinfo` command.

### Wrting Cloud-Optimized GeoTIFF (COG)

A new format called [Cloud-Optimized GeoTIFF (COG)](https://www.cogeo.org/) is making access to such vast amount of imagery easier to access and analyze. A *Cloud-optimized* GeoTIFF is behaves just like a regular GeoTIFF imagery, but instead of downloading the entire image locally, you are able to access *portions* of imagery hosted on a cloud server streamed to clients like QGIS. This makes is very efficient to access this data and even analyze it - without downloading large files. GDAL makes it very easy to create COG files by specifying the `-of COG` option.

```
gdal_translate -of COG merged.vrt merged_cog.tif -co COMPRESS=DEFLATE -co PREDICTOR=2 -a_nodata -9999
```

## Processing Elevation Data


GDAL comes with the `gdaldem` utility that provides a suite of tools for visualizing and analyzing Digital Elevation Models (DEM). The tool supports the following modes

* Hillshade
* Slope
* Aspect
* Color-relief
* Terrain Ruggedness Index (TRI)
* Topographic Position Index (TPI)
* Roughness

Am important point to note is that the x, y and z units of the DEM should be in the same unit. If you are using data in a Geographic CRS (like EPSG:4326) and the height units are meters, you must specify a scale value using `-s` option.

### Creating Hillshade

Let's create a hillshade map from the merged SRTM dataset. The `hillshade` mode creates an 8-bit raster with a nice shaded relief effect. This dataset has X and Y units in degrees and Z units in meters. So we specify `111120` as the scale value.

```
gdaldem hillshade merged.tif hillshade.tif -s 111120
```

`gdaldem` supports multiple hillshading algorithms. Apart from the default, it currently includes the following algorithms.

* Combined shading (`-combined`):  A combination of slope and oblique shading.
* Multidirectional shading (`-multidirectional`): A combination of hillshading illuminated from 225 deg, 270 deg, 315 deg, and 360 deg azimuth.

Let's create a hillshade map with the `-multidirectional` option.

```
gdaldem hillshade merged.tif hillshade_combined.tif -s 111120 -multidirectional
```

```{r echo=FALSE, fig.align='center', out.width='100%'}
knitr::include_graphics('images/gdal/hillshade.png')
```

### Creating Color Relief

A color relief map is an elevation map where different ranges of elevations are colored differently. The `color-relief` mode can create a color relief map with the colors and elevation ranges supplied in a text file. 

Your data package contains a `colormap.txt` file with the following content. The format of the text file is `elevation,red,green,blue` values.

```{bash eval=FALSE, code=readLines('code/gdal/colormap.txt')}
```
We can supply this file to create a colorized elevation map.

```
gdaldem color-relief merged.tif colormap.txt colorized.tif
```

```{r echo=FALSE, fig.align='center', out.width='75%', fig.cap='Color Relief'}
knitr::include_graphics('images/gdal/colorized.png')
```

### Exercise 2

Save the color relief in the PNG format.

### Creating Contours

The GDAL package comes with the utility `gdal_countour` that can create contour lines and polygons from DEMs.

You can specify the internval between contour lines using the  `-i` option.
```
gdal_contour merged.tif contours.gpkg -i 500
```

Running the command with default options generate a vector layer with contours but they do not have any attributes. If you want to label your contour lines in your map, you may want to create contours with elevation values as attribute. You can use the `-a` option and specify the name of the attribute.
```
gdal_contour merged.tif contours.gpkg -i 500 -a elev
```

### Exercise 3

Create polygon contours shapefile from `merged.tif` and name the attributes `MINELEV` and `MAXELEV` represented by each polygon.

## Processing Aerial Imagery

Use the `cd` command to change to the `naip` directory which contains individual aerial imagery tiles in the **JPEG2000** format.

```
cd naip
```

### Create a preview image from source tiles

The source imagery is heavily compressed and cover a large region. Instead of loading the full resolution tiles in a viewer, it is a good practice to create a preview mosaic that can help us assess the coverage and quality of the data.

We first create a *Virtual Raster* mosaic from all the `.jp2` tiles. We can create a text file containing all the files we want to merge. 

**Windows**
```
dir /b *.jp2 > filelist.txt
```

**Mac/Linux**
```
ls *.jp2 > filelist.txt
```

```
gdalbuildvrt -input_file_list filelist.txt naip.vrt
```

We can use the `-outsize` option and specify a percentage to generate a smaller size preview. The below command generates a 2% preview image in the JPEG format.

```
gdal_translate -of JPEG -outsize 2% 2% naip.vrt naip_preview.jpg 
```

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics('images/gdal/naip_preview.jpg')
```


### Mosaic and clip to AOI

```{bash eval=FALSE}
gdalwarp -cutline aoi.shp  -crop_to_cutline naip.vrt aoi.tif -dstnodata 0
```

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics('images/gdal/mosaic.png')
```

### Creating Overviews


### Compressing Imagery for Publishing

[GeoTiff Compression for Dummies](https://blog.cleverelephant.ca/2015/02/geotiff-compression-for-dummies.html)


## Processing Satellite Imagery

This section shows how to take satellite data from Landsat-8 and create various derived products.

### Merging individual bands into RGB composite

```{bash eval=FALSE}
gdal_merge -o rgb.tif -separate ^
  -co PHOTOMETRIC=RGB -co COMPRESS=DEFLATE ^
  landsat8/RT_LC08_L1TP_137042_20190920_20190926_01_T1_2019-09-20_B4.TIF ^
  landsat8/RT_LC08_L1TP_137042_20190920_20190926_01_T1_2019-09-20_B3.TIF ^
  landsat8/RT_LC08_L1TP_137042_20190920_20190926_01_T1_2019-09-20_B2.TIF
```

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics('images/gdal/rgb.png')
```

### Apply Histogram Stretch and Color Correction

```{bash eval=FALSE}
gdal_translate -scale 0 0.3 0 255 -exponent 0.5 -ot Byte ^
  rgb.tif rgb_stretch.tif
```

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics('images/gdal/rgb_stretch.png')
```

### Pan Sharpening

```{bash eval=FALSE}
gdal_pansharpen ^
  landsat8/RT_LC08_L1TP_137042_20190920_20190926_01_T1_2019-09-20_B8.TIF ^
  rgb.tif pansharpened.tif -r bilinear -co COMPRESS=DEFLATE -co PHOTOMETRIC=RGB

gdal_translate -scale 0 0.3 0 255 -exponent 0.5 -ot Byte -a_nodata 0 ^
  pansharpened.tif pansharpened_stretch.tif
```

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics('images/gdal/pansharpen_before.png')
```

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics('images/gdal/pansharpen_after.png')
```

### Raster Algebra

```{bash eval=FALSE}
gdalinfo -stats ^
  landsat8/RT_LC08_L1TP_137042_20190920_20190926_01_T1_2019-09-20_B4.TIF
```
It is important to set nodata value. As seen from the output above, nodata is set to -9999.
 
```{bash eval=FALSE}
gdal_calc ^
  -A landsat8/RT_LC08_L1TP_137042_20190920_20190926_01_T1_2019-09-20_B5.TIF ^
  -B landsat8/RT_LC08_L1TP_137042_20190920_20190926_01_T1_2019-09-20_B4.TIF ^
  --outfile ndvi.tif --calc="(A-B)/(A+B)" --NoDataValue=-9999
```

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics('images/gdal/ndvi.png')
```


## Processing WMS Layers

```
gdalinfo WMS:http://sedac.ciesin.columbia.edu/geoserver/wms
```

[Global Reservoir and Dam (GRanD), v1](https://sedac.ciesin.columbia.edu/data/set/grand-v1-reservoirs-rev01)


```
gdalinfo "WMS:https://sedac.ciesin.columbia.edu/geoserver/wms?SERVICE=WMS&VERSION=1.1.1&REQUEST=GetMap&LAYERS=lulc%3Alulc-global-grid-prob-urban-expansion-2030&SRS=EPSG:4326&BBOX=-179.99997803468415,-55.922762245435266,180.02788233587063,83.97845284575614"
```

```
gdal_translate -of WMS "WMS:https://sedac.ciesin.columbia.edu/geoserver/wms?SERVICE=WMS&VERSION=1.1.1&REQUEST=GetMap&LAYERS=grand-v1%3Agrand-v1-reservoirs-rev01&SRS=EPSG:4326&BBOX=-153.037,-45.881,176.825,70.398" reservoirs.xml
```

```
gdal_translate -outsize 3600 1800 "WMS:https://sedac.ciesin.columbia.edu/geoserver/wms?SERVICE=WMS&VERSION=1.1.1&REQUEST=GetMap&LAYERS=grand-v1%3Agrand-v1-reservoirs-rev01&SRS=EPSG:4326&BBOX=-153.037,-45.881,176.825,70.398" reservoirs.tif
```

Specify a Bounding Box for India

```
gdal_translate -outsize 10000 10000 "WMS:https://sedac.ciesin.columbia.edu/geoserver/wms?SERVICE=WMS&VERSION=1.1.1&REQUEST=GetMap&LAYERS=grand-v1%3Agrand-v1-reservoirs-rev01&SRS=EPSG:4326&BBOX=68.106,6.762,97.412,37.078" reservoirs_india.tif
```

## Georeferencing

### Georeferencing images with corner coordinates

You can easily assign bounding box coordinates to any image using the `a_ullr` option.

```{bash eval=FALSE}
gdalinfo earth_at_night.jpg

gdal_translate -a_ullr -180 90 180 -90 -a_srs EPSG:4326 ^
  earth_at_night.jpg earth_at_night.tif ^
  -co PHOTOMETRIC=RGB -co COMPRESS=DEFLATE

gdalinfo earth_at_night.tif
```

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics('images/gdal/earth_at_night.png')
```

### Georeferencing with GCPs

GCP format is [pixel line X Y]. You can use QGIS Georeferencer to obtain the GCPs. Ideally, this process is used with images that have known corner coordinates. In that case, if you know the image dimensions, pixel and line values can be obtained easily.

Let's georeference this old scanned map.

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics('images/gdal/scanned_map.png')
```

First store the GCPs in the file

```{bash eval=FALSE}
gdal_translate ^
  -gcp 418 893 70 15 ^
  -gcp 380 2432 70 5 ^
  -gcp 3453 2434  90 5 ^
  -gcp 3407 895 90 15 ^
  -gcp 2662 911 85 15 ^
  1870_southern-india.jpg india-with-gcp.tif
```

Next, reproject the image using the GCPs
```{bash eval=FALSE}
gdalwarp -t_srs EPSG:4042 -r bilinear -tr 0.005 0.005 -overwrite ^
  india-with-gcp.tif india-reprojected.tif
```

Try a Thin-plate-spline transformation with some compression options.

```{bash eval=FALSE}
gdalwarp -t_srs EPSG:4042 -tps -r bilinear -tr 0.005 0.005 -overwrite ^
  india-with-gcp.tif india-reprojected.tif ^
  -co COMPRESS=JPEG -co JPEG_QUALITY=50 -co PHOTOMETRIC=YCBCR
```

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics('images/gdal/georeference_gcp.png')
```


# OGR Tools

## Working with CSV files

```
ogrinfo worldcities.csv
```

```
ogrinfo -so -al worldcities.csv
```

```
ogrinfo -so -al worldcities.csv -oo X_POSSIBLE_NAMES=lng -oo Y_POSSIBLE_NAMES=lat
```

```
ogr2ogr -f GPKG worldcities.gpkg worldcities.csv -oo X_POSSIBLE_NAMES=lng -oo Y_POSSIBLE_NAMES=lat 
```

```
ogr2ogr -f GPKG worldcities.gpkg worldcities.csv -oo X_POSSIBLE_NAMES=lng -oo Y_POSSIBLE_NAMES=lat -a_srs EPSG:4326
```

```
ogr2ogr -f GPKG mycities.gpkg worldcities.csv -oo X_POSSIBLE_NAMES=lng -oo Y_POSSIBLE_NAMES=lat -a_srs EPSG:4326  -where "country = 'India'"
```

[OGR SQL Syntax](https://gdal.org/user/ogr_sql_dialect.html#ogr-sql-dialect)

```
ogr2ogr -f GPKG mycities.gpkg worldcities.csv -oo X_POSSIBLE_NAMES=lng -oo Y_POSSIBLE_NAMES=lat -a_srs EPSG:4326 -sql "SELECT city, country, CAST(population AS integer) as population from worldcities where country = 'India'"
```

```
ogr2ogr -f GPKG mycities.gpkg worldcities.csv -oo X_POSSIBLE_NAMES=lng -oo Y_POSSIBLE_NAMES=lat -a_srs EPSG:4326 -sql "SELECT city, country, CAST(population AS integer) as population from worldcities where country = 'India'" -nln mycities
```

## Working with Multiple Layers

### Read Geonames Files

```
<OGRVRTDataSource>
	    <OGRVRTLayer name="CA">
	        <SrcDataSource>CSV:CA.txt</SrcDataSource>
	        <SrcLayer>CA</SrcLayer>
	    </OGRVRTLayer>
</OGRVRTDataSource>
```

```
ogrinfo -al -so CA.vrt
```

### Applying Filters

```
<OGRVRTDataSource>
	    <OGRVRTLayer name="CA">
	        <SrcDataSource>CSV:CA.txt</SrcDataSource>
	        <SrcLayer>CA</SrcLayer>
  	     	<SrcSQL>select * from CA where "FEATCLASS" = 'T'</SrcSQL>
	    </OGRVRTLayer>
</OGRVRTDataSource>
```

```
ogrinfo -al -so CA.vrt
```

### Merging Files

```

<OGRVRTDataSource>
	<OGRVRTUnionLayer name="NA">
	
	    <OGRVRTLayer name="CA">
	        <SrcDataSource>CSV:CA.txt</SrcDataSource>
	        <SrcLayer>CA</SrcLayer>
	     	<SrcSQL>select * from CA where "FEATCLASS" = 'T'</SrcSQL>
	    </OGRVRTLayer>
	
	    <OGRVRTLayer name="MX">
	        <SrcDataSource>CSV:MX.txt</SrcDataSource>
	        <SrcLayer>MX</SrcLayer>
	     	<SrcSQL>select * from MX where "FEATCLASS" = 'T'</SrcSQL>
	    </OGRVRTLayer>
	
	    <OGRVRTLayer name="US">
	        <SrcDataSource>CSV:US.txt</SrcDataSource>
	        <SrcLayer>US</SrcLayer>
	     	<SrcSQL>select * from US where "FEATCLASS" = 'T'</SrcSQL>
	    </OGRVRTLayer>
	
    </OGRVRTUnionLayer>	
</OGRVRTDataSource>
```


```
ogr2ogr -f GPKG NA.gpkg NA.vrt
```


## Geoprocessing and Spatial Queries

```
ogr2ogr -t_srs EPSG:7855 melbourne.gpkg melbourne.gpkg bars_and_pubs -update -nln bars_and_pubs_reprojected
ogr2ogr -t_srs EPSG:7855 melbourne.gpkg melbourne.gpkg metro_stations -update -nln metro_stations_reprojected
```

```
ogr2ogr melbourne.gpkg melbourne.gpkg -update -nln metro_stations_buffer -sql "select m.station, buffer(m.geom, 500) as geom from metro_stations_reprojected m" -dialect SQLITE 
```

You can dissolve the buffers using `ST_COLLECT`

```
ogr2ogr melbourne.gpkg melbourne.gpkg -update -nln metro_stations_buffer_dissolved -sql "select st_union(d.geom) as geom from (select st_collect(buffer(m.geom, 500)) as geom from metro_stations_reprojected m) as d" -dialect SQLITE
```

```
ogr2ogr -t_srs EPSG:4326 melbourne.gpkg melbourne.gpkg -update -nln selected -sql "select  b.* from bars_and_pubs_reprojected as b join metro_stations_buffer_dissolved as m on ST_Within( b.geom, m.geom)" -dialect SQLITE 
```

# Multi Criteria Weighted Overlay Analysis

Multi-criteria analysis is the process of the allocation of land to suit a specific
objective on the basis of a variety of attributes that the selected areas should possess.

Although this is a common GIS operation, it is best performed in the raster space. Below is the typical workflow to take source vector data, transform them to appropriate rasters, re-classify them and perform mathematical operations to do a suitability analysis.

The problem statement is **Locate the suitable areas for development**, that are

* Close to roads
* Away from waterbodies
* Not in protected areas

## Rasterize vector layers

For overlay analysis, all rasters must be of the same extent. So we first find the extent of the dataset that we can use while rasterizing.

```{bash eval=FALSE}
ogrinfo -so osm/assam.gpkg boundary
```

```{bash eval=FALSE}
gdal_rasterize -ot Int16 -burn 1 -tr 15 15 -te 170134 2669018 798842 3097324 ^
  osm/assam.gpkg -l roads roads.tif
```

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics('images/gdal/roads_raster.png')
```

```{bash eval=FALSE}
gdal_rasterize -ot Int16 -burn 1 -tr 15 15 -te 170134 2669018 798842 3097324 ^
  osm/assam.gpkg -l boundary boundary.tif
```

Use `-i` for inverse rasterization. We want to rasterize 'un-protected' areas

```{bash eval=FALSE}
gdal_rasterize -i -ot Int16 -burn 1 -tr 15 15 -te 170134 2669018 798842 3097324 ^
  osm/assam.gpkg -l protected_regions protected_regions.tif
```

We need a water layer, but the source data has a polygon and a polyline water features layer. We create 2 rasters and then add them to create a single water features raster.

```{bash eval=FALSE}
gdal_rasterize -ot Int16 -burn 1 -tr 15 15 -te 170134 2669018 798842 3097324 ^
  osm/assam.gpkg -l water_polygons water_polygons.tif

gdal_rasterize -ot Int16 -burn 1 -tr 15 15 -te 170134 2669018 798842 3097324 ^
  osm/assam.gpkg -l water_polylines water_polylines.tif


gdal_calc -A water_polygons.tif -B water_polylines.tif ^
  --outfile water_add.tif --calc="A+B"

gdal_calc -A water_add.tif --outfile water.tif ^
  --calc="A>0"
```

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics('images/gdal/water_raster.png')
```

## Generate proximity (Euclidean distance) rasters
```{bash eval=FALSE}
gdal_proximity roads.tif roads_proximity.tif ^
  -ot Int16 -distunits GEO

gdal_proximity water.tif water_proximity.tif ^
  -ot Int16 -distunits GEO
```

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics('images/gdal/roads_proximity.png')
```

## Re-classify raster values

**Roads** Give higher score to nearer pixels

0-1000m --> 100

1000-5000m --> 50

\>5000m --> 10

```{bash eval=FALSE}
gdal_calc -A roads_proximity.tif --outfile roads_class.tif ^
  --calc="100*(A<=1000) + 50*(A>1000)*(A<=5000) + 10*(A>5000)"
```

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics('images/gdal/roads_class.png')
```

**Water** Give lower score to nearer pixels

0-1000m --> 10

1000 -5000m ---> 50

\>5000m --> 100

```{bash eval=FALSE}
gdal_calc -A water_proximity.tif --outfile water_class.tif ^
  --calc="100*(A>5000) + 50*(A>1000)*(A<=5000) + 10*(A<1000)"
```

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics('images/gdal/water_class.png')
```

## Overlay analysis

Roads and Water have a range of values, but protected areas are either 0 or 1. So we combine these together accordingly.

```{bash eval=FALSE}
gdal_calc ^
  -A roads_class.tif -B water_class.tif -C protected_regions.tif -D boundary.tif ^
  --outfile suitability.tif --calc="(A + B)*(C>0)*D" --NoDataValue=0
```

Smooth the output
```{bash eval=FALSE}
gdalwarp -r cubicspline -tr 60 60 -dstnodata 0 ^
  suitability.tif suitability_final.tif
```

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics('images/gdal/suitability.png')
```

# Running commands in batch

You can run the GDAL/OGR commands in a loop using Python. Open OSGeo4W Shell and type the following to set the correct system paths

```{bash eval=FALSE}
py3_env
```

Say you want to convert the format of the images from JPEG200 to GeoTiff. You would run a command such as below.

```{bash eval=FALSE}
gdal_translate -of GTiff -co COMPRESS=JPEG {input} {output}
```

But it would be a lot of manual effort if you want to run the commands on hundreds of input files. Here's where a simple python script can help you automate running the commands in a batch. The data directory contains a file called `batch.py` with the following python code.

```{python eval=FALSE, code=readLines('code/gdal/batch.py')}
```

In OsGeo4W shell, run the following command to start batch processing on all tiles contained in the `naip/` directory.

```{bash eval=FALSE}
python3 batch.py
```

The data directory also contains an example of running the batch commands in parallel using python's built-in multiprocessing library. If your system has multi-core CPU, running commands in parallel like this on multiple threads can give you performance boost over running them in series.

```{python eval=FALSE, code=readLines('code/gdal/batch_parallel.py')}
```

The script runs the commands both in parallel and serial mode and prints the time taken by each of them.

```{bash eval=FALSE}
python3 batch-parallel.py
```

# Supplement

## Creating Colorized Hillshade

If you want to merge hillshade and color-relief to create a colored shaded relief map, you can use use `gdal_calc.py` to create do gamma and overlay calculations to combine the 2 rasters. [^1]

[^1]: Code reference https://gis.stackexchange.com/questions/255537/merging-hillshade-dem-data-into-color-relief-single-geotiff-with-qgis-and-gdal

```
gdal_calc.py -A hillshade.tif --outfile=gamma_hillshade.tif \
  --calc="uint8(((A / 255.)**(1/0.5)) * 255)"
```

```
gdal_calc.py -A gamma_hillshade.tif -B colorized.tif --allBands=B \
--calc="uint8( ( \
                 2 * (A/255.)*(B/255.)*(A<128) + \
                 ( 1 - 2 * (1-(A/255.))*(1-(B/255.)) ) * (A>=128) \
               ) * 255 )" --outfile=colorized_hillshade.tif
```               


```{r echo=FALSE, fig.align='center', out.width='75%', fig.cap='Colorized Shaded Relief'}
knitr::include_graphics('images/gdal/colorized_hillshade.png')
```


# Resources
* [GDAL Tips](https://twitter.com/gdaltips) `@gdaltips` on Twitter

# Data Credits

* OpenStreetMap (osm) data layers: Data/Maps Copyright 2019 Geofabrik GmbH and OpenStreetMap Contributors. [OSM India free extract](https://download.geofabrik.de/asia/india.html) downloaded from Geofabrik.
* Landsat: Landsat-8 image courtesy of the U.S. Geological Survey. Image downloaded from [Google Cloud Platform](https://console.cloud.google.com/marketplace/details/usgs-public-data/landast) and pre-processed using [Semi Automatic Classification Plugin from QGIS](https://fromgistors.blogspot.com/p/semi-automatic-classification-plugin.html)
* Earth at Night image: Credit: NASA Earth Observatory/NOAA NGDC. Earth at Night flat hi-resolution map downloaded from [NASA earth observatory](https://earthobservatory.nasa.gov/features/NightLights/page3.php)
* William Mackenzie 1870 map of Southern India:  out-of-copyright scanned map downloaded from [Hipkiss’s Scanned Old Maps](http://www.hipkiss.org/data/maps.html)
* NAIP 2016 Aerial Imagery for California: The National Agriculture Imagery Program (NAIP). USDA-FSA-APFO Aerial Photography Field Office. Downloaded from [NRCS](https://nrcs.app.box.com/v/naip/folder/18144379349)

# License

This course material is licensed under a [Creative Commons Attribution-NonCommercial 4.0 International License](https://creativecommons.org/licenses/by-nc/4.0/). You are free to use the material for any non-commercial purpose. Kindly give appropriate credit to the original author.

&copy; 2020 Ujaval Gandhi [www.spatialthoughts.com](http://spatialthoughts.com)

***

**This course is offered as an instructor-led online class. Visit [Spatial Thoughts](https://spatialthoughts.com/events/) to know details of upcoming sessions.**
