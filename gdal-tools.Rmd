---
title: "Mastering GDAL Tools (Full Course Material)"
subtitle: "Satellite and aerial image processing using GDAL tools"
author: "Ujaval Gandhi"
fontsize: 12pt
output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: 3
    highlight: pygments
    includes:
      after_body: disqus.html
  # pdf_document:
  #   toc: yes
  #   toc_depth: 3
  # word_document:
  #   toc: yes
  #   toc_depth: '3'
header-includes:
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \renewcommand{\footrulewidth}{0.4pt}
- \fancyhead[LE,RO]{\thepage}
- \geometry{left=1in,top=0.75in,bottom=0.75in}
- \fancyfoot[CE,CO]{{\includegraphics[height=0.5cm]{images/cc-by-nc.png}} Ujaval Gandhi http://www.spatialthoughts.com}
classoption: a4paper
---

\newpage

***

```{r echo=FALSE, fig.align='center', out.width='250pt'}
knitr::include_graphics('images/spatial_thoughts_logo.png')
```

***

\newpage

# Introduction 

[GDAL](https://gdal.org/)  is an open-source library for raster and vector geospatial data formats. The library comes with a vast collection of utility programs that can perform many geoprocessing tasks. This class introduces GDAL and OGR utilities with example workflows for processing raster and vector data. The class also shows how to use these utility programs to build Spatial ETL pipelines and do batch processing.


[![View Presentation](images/gdal/introduction.png){width="400px"}](https://docs.google.com/presentation/d/1JvGjb5eNM9F--zfyTFAeAk0R5UG6weFpOUVDVkJSnho/edit?usp=sharing
){target="_blank"}

[View the Presentation &#8599;](https://docs.google.com/presentation/d/1JvGjb5eNM9F--zfyTFAeAk0R5UG6weFpOUVDVkJSnho/edit?usp=sharing){target="_blank"}


# Get the Data Package

The code examples in this class use a variety of datasets. All the required datasets are supplied to you in the ``gdal_tools.zip`` file. Unzip this file to the `Downloads` directory. All commands below assume the data is available in the ``<home folder>/Downloads/gdal_tools/`` directory.

*Not enrolled in our instructor-led class but want to work through the material on your own?* [Get free access to the data package](https://docs.google.com/forms/d/e/1FAIpQLScfS6sICXfbAfPr2MOAkfAIbpj8G6v3FR_YtMRGOoKrDnDBtw/viewform){target="_blank"}

# Software

This courses requires installing the GDAL package. Along with GDAL, we highly recommend installing QGIS to view the result of the command-line operations. You will find installation instructions for both the software below.

## GDAL

The preferred method for installing the GDAL Tools is via Anaconda. Follow these steps to install Anaconda and the GDAL library.

[Download the Anaconda Installer](https://www.anaconda.com/products/individual) for Python 3.7 (or a higher version) for your operating system. Once downloaded, double click the installer and install it into the default suggested directory.

*Note: If your username has spaces, or non-English characters, it causes problems. In that case, you can install it to a path such as  `C:\anaconda`.*

```{r echo=FALSE, fig.align='center', out.width='75%'}
knitr::include_graphics('images/gdal/conda.png')
```

### Windows

Once Anaconda installed, search for *Anaconda Prompt* in the Start Menu and launch a new window.

1. Create a new environment named `gdal`. When prompted to confirm, type `y` and press *Enter*.

```
conda create --name gdal
```
> Note: You can use the shortcut *Shift + Insert* to paste commands in Anaconda Prompt.

```{r echo=FALSE, fig.align='center', out.width='75%'}
knitr::include_graphics('images/gdal/condawin1.png')
```

2. Activate the environment and install the `gdal` package. When prompted to confirm, type `y` and press *Enter*.

```
conda activate gdal
conda install -c conda-forge gdal
```


```{r echo=FALSE, fig.align='center', out.width='75%'}
knitr::include_graphics('images/gdal/condawin2.png')
```

3. Once the installation finishes, verify if you are able to run the GDAL tools. Type the following command and check if a version number is printed.

```
gdalinfo --version
```

> The version number displayed for you may be slightly different. As long as you do not get a `command not found` error, you should be set for the class.


```{r echo=FALSE, fig.align='center', out.width='75%'}
knitr::include_graphics('images/gdal/condawin3.png')
```

### Mac/Linux

Once Anaconda is installed, launch a *Terminal* window.

1. Create a new environment named `gdal`. When prompted to confirm, type `y` and press *Enter*.

```
conda create --name gdal
```

```{r echo=FALSE, fig.align='center', out.width='75%'}
knitr::include_graphics('images/gdal/condamac1.png')
```

2. Activate the environment and install the `gdal` package. When prompted to confirm, type `y` and press *Enter*.

```
conda activate gdal
conda install -c conda-forge gdal
```

```{r echo=FALSE, fig.align='center', out.width='75%'}
knitr::include_graphics('images/gdal/condamac2.png')
```

3. Once the installation finishes, verify if you are able to run the GDAL tools. Type the following command and check if a version number is printed.

```
gdalinfo --version
```

> The version number displayed for you may be slightly different. As long as you do not get a `command not found` error, you should be set for the class.

```{r echo=FALSE, fig.align='center', out.width='75%'}
knitr::include_graphics('images/gdal/condamac3.png')
```

## QGIS 

This course uses QGIS LTR version 3.16 for visualization of results. It is not mandatory to install QGIS, but highly recommended.

Please review [QGIS-LTR Installation Guide](install-qgis-ltr.html) for step-by-step instructions.

# Getting Familiar with the Command Prompt

All the commands in the exercises below are expected to be run from the *Anaconda Prompt* on Windows or a *Terminal* on Mac/Linux. We will now cover basic terminal commands that will help you get comfortable with the environment

### Windows


|   **Command**    | **Description**                     | **Example**     |
|:-----------------|:------------------------------------|:---------------------|
| `cd`             | Change directory                    | `cd Downloads\gdal-tools` |
| `cd ..`          | Change to the parent directory      | `cd ..` |
| `dir`            | List files in the current directory | `dir` |
| `del`            | Delete a file                       | `del test.txt` |
| `rmdir`          | Delete a directory                  | `rmdir /s test` |
| `type`           | Print the contents of a file        | `type test.txt` |
| `> output.txt`   | Redirect the output to a file       | `dir /b *.csv > output.txt` |
| `cls`            | Clear screen                        | `cls` |


### Mac/Linux

|   **Command**    | **Description**                     | **Example**     |
|:-----------------|:------------------------------------|:---------------------|
| `cd`             | Change directory                    | `cd Downloads/gdal-tools` |
| `cd ..`          | Change to the parent directory      | `cd ..` |
| `ls`             | List files in the current directory | `ls` |
| `rm `            | Delete a file                       | `rm test.txt` |
| `rm -R`          | Delete a directory                  | `rm -R test` |
| `cat`            | Print the contents of a file        | `cat test.txt` |
| `> output.txt`   | Redirect the output to a file       | `ls *.csv > output.txt` |
| `clear`          | Clear screen                        | `clear` |


# GDAL Tools

## Basic Raster Processing

We will start learning the basic GDAL commands by processsing elevation rasters from SRTM. In the *Command Prompt* window, use the `cd` command to change to the `srtm` directory which 4 individual SRTM tiles around the Mt. Everest region.

```
cd srtm
```

Use the `gdalinfo` command to check the information about a single image. 
```
gdalinfo N27E086.hgt
```

```{r echo=FALSE, fig.align='center', out.width='75%'}
knitr::include_graphics('images/gdal/gdalinfo1.png')
```

A useful parameter is `-stats` which computes and displays image statistics. Run it on the raster to get some statistics of pixel values in the image.
```
gdalinfo -stats N27E086.hgt
```

```{r echo=FALSE, fig.align='center', out.width='75%'}
knitr::include_graphics('images/gdal/gdalinfo2.png')
```

### Merging Tiles

We will now merge the 4 neighboring SRTM tiles into 1 raster so we can work with them together. GDAL provides a useful format called [Virtual Raster](https://gdal.org/drivers/raster/vrt.html) that allows us to create a *Virtual* file with `.vrt` extension that is a pointer to multiple source files. A `.vrt` file is just a text file, so it doesn't consume any disk space but allows us to run any GDAL command as if it was a raster file. 

First we need to create a text file containing all the files we want to merge. We can use the `dir` command on Windows prompt list the files matching the pattern `*.hgt` and redirect the output to a file. Here the `/b` option runs the command in the *Bare* mode which excludes all info except file names. 

**Windows**
```
dir /b *.hgt > filelist.txt
```

On Mac/Linux systems, the same came be achieved using the `ls` command.

**Mac/Linux**
```
ls *.hgt > filelist.txt
```

Once the command finishes, verify that the `filelist.txt` has the names of the source tiles.

```{r echo=FALSE, fig.align='center', out.width='50%'}
knitr::include_graphics('images/gdal/merging1.png')
```

We can now use the `gdalbuildvrt` command to create a virtual raster from the source files in the `filelist.txt`.

```
gdalbuildvrt -input_file_list filelist.txt merged.vrt
```

```{r echo=FALSE, fig.align='center', out.width='100%'}
knitr::include_graphics('images/gdal/merging2.png')
```

> Note: We could have done this operation in a  single step using the command `gdalbuildvrt merged.vrt *.hgt`. However, some versions of GDAL on Windows do not expand the `*` wildcard correctly and the command results in an error. It is recommended to use a filelist instead of wildcards with GDAL commands on Windows to avoid unexpeted results.[[reference](https://github.com/OSGeo/gdal/issues/1749)]

### Exercise 1

Can you find out what is the highest elevation value in the merged raster? Since these rasters are around the Mt.Everest region, the *MAXIMUM* value will be the elevation of the summit.


```{r echo=FALSE, fig.align='center', out.width='75%'}
knitr::include_graphics('images/gdal/exercise1.png')
```

### Converting Formats

Let's conver the *Virtual Raster* to a GeoTIFF file. `gdal_translate` program allows us to convert between any of the hundreds of data formats supported by GDAL. The format is automatically guessed from the file extension. Alternatively, you can also specify it using the `-of` option with the [short name of the format](https://gdal.org/drivers/raster/index.html) such a **GTiff**.
```
gdal_translate -of GTiff merged.vrt merged.tif
```

```{r echo=FALSE, fig.align='center', out.width='75%'}
knitr::include_graphics('images/gdal/compression1.png')
```

### Compressing Output

The default output GeoTIFF file is uncompressed - meaning each pixel's value is stored on the disk without any further processing. For large rasters, this can consume a lot of disk space. A smarter approach is to use a lossless compression algorithm to reduce the size of the raster while maintaining full fidelity of the original data. GDAL supports many compression algorithm out-of-the-box and can be specified with GDAL commands using the `-co` option. The most popular loss-less compression algorithms are **DEFLATE**, **LZW** and **PACKBITS**. We can try the `DEFLATE` algorithm on our dataset.

```
gdal_translate -of GTiff merged.vrt merged.tif -co COMPRESS=DEFLATE
```

```{r echo=FALSE, fig.align='center', out.width='75%'}
knitr::include_graphics('images/gdal/compression2.png')
```


The uncompressed filesize was **100+ MB**. After applying the  *DEFLATE* compression, the file size reduced to **72MB**. We can further reduce the file size by specifying additional options. The `PREDICTOR` option helps compress data better when the neighboring values are correlated. For elevation data, this is definitely the case. The `TILED` option will compress the data in blocks rather than line-by-line.

```
gdal_translate -of GTiff merged.vrt merged.tif -co COMPRESS=DEFLATE -co TILED=YES -co PREDICTOR=2
```

```{r echo=FALSE, fig.align='center', out.width='75%'}
knitr::include_graphics('images/gdal/compression3.png')
```

The resulting file now comes out much smaller at **39MB**. Check this article [GeoTIFF compression and optimization with GDAL](https://kokoalberti.com/articles/geotiff-compression-optimization-guide/) to learn more about various options and compression algorithms. 

### Setting NoData Values

The output from `gdalinfo` command shows that the original data has a *NoData* Value set to `-32768`. We can set a new *NoData* value. The `-a_nodata` option allows us to specify a new value.

```
gdal_translate -of GTiff merged.vrt merged.tif -co COMPRESS=DEFLATE -co TILED=YES -co PREDICTOR=2 -a_nodata -9999
```

After running the command, you can verify the results using the `gdalinfo` command.

### Wrting Cloud-Optimized GeoTIFF (COG)

A new format called [Cloud-Optimized GeoTIFF (COG)](https://www.cogeo.org/) is making access to such vast amount of imagery easier to access and analyze. A *Cloud-optimized* GeoTIFF is behaves just like a regular GeoTIFF imagery, but instead of downloading the entire image locally, you are able to access *portions* of imagery hosted on a cloud server streamed to clients like QGIS. This makes is very efficient to access this data and even analyze it - without downloading large files. GDAL makes it very easy to create COG files by specifying the `-of COG` option.

```
gdal_translate -of COG merged.vrt merged_cog.tif -co COMPRESS=DEFLATE -co PREDICTOR=2 -a_nodata -9999
```

## Processing Elevation Data


GDAL comes with the `gdaldem` utility that provides a suite of tools for visualizing and analyzing Digital Elevation Models (DEM). The tool supports the following modes

* Hillshade
* Slope
* Aspect
* Color-relief
* Terrain Ruggedness Index (TRI)
* Topographic Position Index (TPI)
* Roughness

Am important point to note is that the x, y and z units of the DEM should be in the same unit. If you are using data in a Geographic CRS (like EPSG:4326) and the height units are meters, you must specify a scale value using `-s` option.

### Creating Hillshade

Let's create a hillshade map from the merged SRTM dataset. The `hillshade` mode creates an 8-bit raster with a nice shaded relief effect. This dataset has X and Y units in degrees and Z units in meters. So we specify `111120` as the scale value.

```
gdaldem hillshade merged.tif hillshade.tif -s 111120
```

`gdaldem` supports multiple hillshading algorithms. Apart from the default, it currently includes the following algorithms.

* Combined shading (`-combined`):  A combination of slope and oblique shading.
* Multidirectional shading (`-multidirectional`): A combination of hillshading illuminated from 225 deg, 270 deg, 315 deg, and 360 deg azimuth.

Let's create a hillshade map with the `-multidirectional` option.

```
gdaldem hillshade merged.tif hillshade_combined.tif -s 111120 -multidirectional
```

```{r echo=FALSE, fig.align='center', out.width='100%'}
knitr::include_graphics('images/gdal/hillshade.png')
```

### Creating Color Relief

A color relief map is an elevation map where different ranges of elevations are colored differently. The `color-relief` mode can create a color relief map with the colors and elevation ranges supplied in a text file. 

Your data package contains a `colormap.txt` file with the following content. The format of the text file is `elevation,red,green,blue` values.

```{bash eval=FALSE, code=readLines('code/gdal/colormap.txt')}
```
We can supply this file to create a colorized elevation map.

```
gdaldem color-relief merged.tif colormap.txt colorized.tif
```

```{r echo=FALSE, fig.align='center', out.width='75%', fig.cap='Color Relief'}
knitr::include_graphics('images/gdal/colorized.png')
```

### Exercise 2

Save the color relief in the PNG format.

### Creating Contours

The GDAL package comes with the utility `gdal_countour` that can create contour lines and polygons from DEMs.

You can specify the internval between contour lines using the  `-i` option.
```
gdal_contour merged.tif contours.gpkg -i 500
```

Running the command with default options generate a vector layer with contours but they do not have any attributes. If you want to label your contour lines in your map, you may want to create contours with elevation values as attribute. You can use the `-a` option and specify the name of the attribute.
```
gdal_contour merged.tif contours.gpkg -i 500 -a elev
```

### Exercise 3

Create polygon contours shapefile from `merged.tif` and name the attributes `MINELEV` and `MAXELEV` represented by each polygon.

## Processing Aerial Imagery

Use the `cd` command to change to the `naip` directory which contains individual aerial imagery tiles in the **JPEG2000** format.

```
cd naip
```

### Create a preview image from source tiles

The source imagery is heavily compressed and cover a large region. Instead of loading the full resolution tiles in a viewer, it is a good practice to create a preview mosaic that can help us assess the coverage and quality of the data.

We first create a *Virtual Raster* mosaic from all the `.jp2` tiles. We can create a text file containing all the files we want to merge. 

**Windows**
```
dir /b *.jp2 > filelist.txt
```

**Mac/Linux**
```
ls *.jp2 > filelist.txt
```

```
gdalbuildvrt -input_file_list filelist.txt naip.vrt
```

We can use the `-outsize` option and specify a percentage to generate a smaller size preview. The below command generates a 2% preview image in the JPEG format.

```
gdal_translate -of JPEG -outsize 2% 2% naip.vrt naip_preview.jpg 
```

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics('images/gdal/naip_preview.jpg')
```

### Create a Tile Index

When working with large amounts of imagery tiles, it is useful to generate a tile index. A tile index layer is a polygon layer with the bounding box of each tile. An index layer allows us to check the coverage of the source data and locate specific tiles. It is a simple but effective way to catalog raster data from a hard drive or from a folder on your computer.

`gdaltindex` command creates a tile index from a list of input files. Here we can use the `--optfile` option to supply the list of files via a file.

```
gdaltindex -write_absolute_path index.shp --optfile filelist.txt
```

### Mosaic and clip to AOI

Let's say we want to mosaic all the source tile into a single image. We also want to clip the mosaic to a given AOI.

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics('images/gdal/aoiselection.png')
```

We can use the `gdalwarp` utility to clip the raster using the `-cutline` option. We can also add JPEG compression to the output file to reduce the file size. Refer to the post [GeoTiff Compression for Dummies](https://blog.cleverelephant.ca/2015/02/geotiff-compression-for-dummies.html) by Paul Ramsey that gives more insights into compression imagery. 

> Note that JPEG is a lossy compression method and is suited only for photographic rasters such as aerial/drone imagery. For scientific datasets, you should always use lossless compression as shown in the [previous section](#compressing-output).

```
gdalwarp -cutline aoi.shp  -crop_to_cutline naip.vrt aoi.tif -co COMPRESS=JPEG -co TILED=YES -co PHOTOMETRIC=YCBCR
```

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics('images/gdal/mosaic.png')
```

### Tips for Improving Performance

`gdalwarp` utility supports multithreaded processing. There are 2 different options for parallel processing.

* `-multi`: This option parallelizes I/O and CPU operations.
* `-wo NUM_THREADS=ALL_CPUS`: This option parallelizes CPU operations over several cores.

There is also another option that allows `gdalwarp` to use more RAM for caching. This option is very helpful to speed up operations on large rasters

* `-wm`: Set a higher memory for caching

All of these options can be combined that may result in faster processing of the data.

```
gdalwarp -cutline aoi.shp  -crop_to_cutline naip.vrt aoi.tif -co COMPRESS=JPEG -co TILED=YES -co PHOTOMETRIC=YCBCR -multi -wo NUM_THREADS=ALL_CPUS -wm 512
```


### Creating Overviews

If you try loading the resulting raster into a viewer, you will notice that it takes a lot of time for it to render. Zoom/Pan operations are quite slow as well. This is because the viewer is rendering all the pixels at native resolution. Since this is a very high resolution dataset, it requires processing a lot of pixels, even if you are zoomed out. A common solution to this problem is to create *Pyramid Tiles* or *Overviews*. This process creates low resolution versions of the image by averaging pixel values from higher resolution pixels. If the pyramid tiles are present, imagery viewers can use it to speed up the rendering process. GDAL provides the utility `gdaladdo` to create overview tiles. GeoTIFF format supports storing the overviews within the file itself. For other formats, the program generates external overviews in the `.ovr` format.

You can run the `gdaladdo` (**GDAL**-**Add**-**O**verview) command with default options to create internal overviews. Once the overviews are created, try opening the `aoi.tif` in QGIS. You will see that it renders much faster and zoom/pan operations are very smooth.
```
gdaladdo aoi.tif
```

The default overviews use the nearest neighbor resampling. We can pick any resampling method from the many available algorithms. We can try the bilinear interpolation using the `-r bilinear` option. Since the source imagery is JPEG compressed, we can compress the overviews with the same compression.

```
gdaladdo -r bilinear --config COMPRESS_OVERVIEW JPEG aoi.tif
```

## Processing Satellite Imagery

This section shows how to take satellite data from Landsat-8 and create various derived products. Use the `cd` command to change to the `landsat8` directory which contains Landsat-8 imagery. This diretory has 5 individual GeoTIFF files for 5 different bands from a single landsat-8 scene.

```
cd landsat8
```

### Merging individual bands into RGB composite

Let's create a RGB composite image by combining thee 3 different bands - Red, Green and Blue - into a single image. We can use the `gdal_merge.py` command to merge different images. Here we must use the `-separate` option which tells the command to place each image in a separate band.

```
gdal_merge.py -o rgb.tif -separate -co PHOTOMETRIC=RGB -co COMPRESS=DEFLATE RT_LC08_L1TP_137042_20190920_20190926_01_T1_2019-09-20_B4.TIF RT_LC08_L1TP_137042_20190920_20190926_01_T1_2019-09-20_B3.TIF RT_LC08_L1TP_137042_20190920_20190926_01_T1_2019-09-20_B2.TIF
```

Once the command finishes, you can view the result in QGIS. 

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics('images/gdal/rgb.png')
```

### Apply Histogram Stretch and Color Correction

The resulting composite appears quite dark and has low-contrast. QGIS applies a default contrast stretch based on the mimimum and maximum values in the image. Due to the presence of clouds and cloud-shadows - there are outlier pixels which make the default contrast stretch not optimal.

Here's what the histogram of the RGB composite looks like.

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics('images/gdal/histogram.png')
```


We can apply a histogram stretch to increase the contrast. This is done using the `-scale` option. Since most of the pixels have a value between 0 and 0.3, we can choose these are minimum and maximum values and apply a contrast stretch to make them go from 0 to 255. The resulting image will be a 8-bit color image where the input pixel values are linearly scaled to the target value.

> Note: Scaling the image will alter the pixel values. The resulting image is suitable for visualizaion, but they should never be used for analysis. Scientific analysis should always use the un-scaled pixel values.

```
gdal_translate -scale 0 0.3 0 255 -ot Byte rgb.tif rgb_stretch.tif
```


```{r echo=FALSE, fig.align='center', out.width='75%', fig.cap='RGB Composite with Linear Stretch'}
knitr::include_graphics('images/gdal/rgb_stretch_linear.png')
```

We can also apply a non-linear stretch. `gdal_translate` has a `-exponent` option that scales the input values using the following formula. Choosing an exponent value between 0 and 1 will enhance low inensity values - resulting in a brighter image. [Learn more &#8599;    ](https://homepages.inf.ed.ac.uk/rbf/HIPR2/pixexp.htm)

Let's try exponent value of **0.5**. The result is a much better looking output.
```
gdal_translate -scale 0 0.3 0 255 -exponent 0.5 -ot Byte rgb.tif rgb_stretch.tif
```

```{r echo=FALSE, fig.align='center', out.width='75%', fig.cap='RGB Composite with Exponential Stretch'}
knitr::include_graphics('images/gdal/rgb_stretch_exponent.png')
```

### Exercise 4

Create a NRG Composite image with Near Infrared, Red and Green bands. Apply a contrast stretch to the result and save it as a PNG image.

```{r echo=FALSE, fig.align='center', out.width='75%', fig.cap='NRG Composite'}
knitr::include_graphics('images/gdal/nrg_stretch.png')
```

### Pan Sharpening

```
gdal_pansharpen.py RT_LC08_L1TP_137042_20190920_20190926_01_T1_2019-09-20_B8.TIF rgb.tif pansharpened.tif -r bilinear -co COMPRESS=DEFLATE -co PHOTOMETRIC=RGB
```

```
gdal_translate -scale 0 0.3 0 255 -exponent 0.5 -ot Byte -a_nodata 0 pansharpened.tif pansharpened_stretch.tif
```

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics('images/gdal/pansharpen_before.png')
```

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics('images/gdal/pansharpen_after.png')
```

### Raster Algebra

```
gdalinfo -stats landsat8/RT_LC08_L1TP_137042_20190920_20190926_01_T1_2019-09-20_B4.TIF
```
It is important to set nodata value. As seen from the output above, nodata is set to -9999.
 
```
gdal_calc.py -A RT_LC08_L1TP_137042_20190920_20190926_01_T1_2019-09-20_B5.TIF -B RT_LC08_L1TP_137042_20190920_20190926_01_T1_2019-09-20_B4.TIF --outfile ndvi.tif --calc="(A-B)/(A+B)" --NoDataValue=-9999
```

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics('images/gdal/ndvi.png')
```


## Processing WMS Layers

```
gdalinfo WMS:http://sedac.ciesin.columbia.edu/geoserver/wms
```

[Global Reservoir and Dam (GRanD), v1](https://sedac.ciesin.columbia.edu/data/set/grand-v1-reservoirs-rev01)


```
gdalinfo "WMS:https://sedac.ciesin.columbia.edu/geoserver/wms?SERVICE=WMS&VERSION=1.1.1&REQUEST=GetMap&LAYERS=lulc%3Alulc-global-grid-prob-urban-expansion-2030&SRS=EPSG:4326&BBOX=-179.99997803468415,-55.922762245435266,180.02788233587063,83.97845284575614"
```

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics('images/gdal/wms2.png')
```

```
gdal_translate -of WMS "WMS:https://sedac.ciesin.columbia.edu/geoserver/wms?SERVICE=WMS&VERSION=1.1.1&REQUEST=GetMap&LAYERS=grand-v1:Agrand-v1-reservoirs-rev01" reservoirs.xml
```

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics('images/gdal/wms3.png')
```

```
gdal_translate -outsize 3600 1800 "WMS:https://sedac.ciesin.columbia.edu/geoserver/wms?SERVICE=WMS&VERSION=1.1.1&REQUEST=GetMap&LAYERS=grand-v1%3Agrand-v1-reservoirs-rev01&SRS=EPSG:4326&BBOX=-153.037,-45.881,176.825,70.398" reservoirs.tif
```

Specify a Bounding Box for India

```
gdal_translate -outsize 10000 10000 "WMS:https://sedac.ciesin.columbia.edu/geoserver/wms?SERVICE=WMS&VERSION=1.1.1&REQUEST=GetMap&LAYERS=grand-v1%3Agrand-v1-reservoirs-rev01&SRS=EPSG:4326&BBOX=68.106,6.762,97.412,37.078" reservoirs_india.tif
```

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics('images/gdal/wms4.png')
```

## Georeferencing

### Georeferencing images with corner coordinates

You can easily assign bounding box coordinates to any image using the `a_ullr` option.

```{bash eval=FALSE}
gdalinfo earth_at_night.jpg

gdal_translate -a_ullr -180 90 180 -90 -a_srs EPSG:4326 ^
  earth_at_night.jpg earth_at_night.tif ^
  -co PHOTOMETRIC=RGB -co COMPRESS=DEFLATE

gdalinfo earth_at_night.tif
```

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics('images/gdal/earth_at_night.png')
```

### Georeferencing with GCPs

GCP format is [pixel line X Y]. You can use QGIS Georeferencer to obtain the GCPs. Ideally, this process is used with images that have known corner coordinates. In that case, if you know the image dimensions, pixel and line values can be obtained easily.

Let's georeference this old scanned map.

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics('images/gdal/scanned_map.png')
```

First store the GCPs in the file

```{bash eval=FALSE}
gdal_translate ^
  -gcp 418 893 70 15 ^
  -gcp 380 2432 70 5 ^
  -gcp 3453 2434  90 5 ^
  -gcp 3407 895 90 15 ^
  -gcp 2662 911 85 15 ^
  1870_southern-india.jpg india-with-gcp.tif
```

Next, reproject the image using the GCPs
```{bash eval=FALSE}
gdalwarp -t_srs EPSG:4042 -r bilinear -tr 0.005 0.005 -overwrite ^
  india-with-gcp.tif india-reprojected.tif
```

Try a Thin-plate-spline transformation with some compression options.

```{bash eval=FALSE}
gdalwarp -t_srs EPSG:4042 -tps -r bilinear -tr 0.005 0.005 -overwrite ^
  india-with-gcp.tif india-reprojected.tif ^
  -co COMPRESS=JPEG -co JPEG_QUALITY=50 -co PHOTOMETRIC=YCBCR
```

```{r echo=FALSE, fig.align='center'}
knitr::include_graphics('images/gdal/georeference_gcp.png')
```


# OGR Tools

## Working with CSV files

```
ogrinfo worldcities.csv
```

```
ogrinfo -so -al worldcities.csv
```

```
ogrinfo -so -al worldcities.csv -oo X_POSSIBLE_NAMES=lng -oo Y_POSSIBLE_NAMES=lat
```

```
ogr2ogr -f GPKG worldcities.gpkg worldcities.csv -oo X_POSSIBLE_NAMES=lng -oo Y_POSSIBLE_NAMES=lat 
```

```
ogr2ogr -f GPKG worldcities.gpkg worldcities.csv -oo X_POSSIBLE_NAMES=lng -oo Y_POSSIBLE_NAMES=lat -a_srs EPSG:4326
```

```
ogr2ogr -f GPKG mycities.gpkg worldcities.csv -oo X_POSSIBLE_NAMES=lng -oo Y_POSSIBLE_NAMES=lat -a_srs EPSG:4326  -where "country = 'India'"
```

[OGR SQL Syntax](https://gdal.org/user/ogr_sql_dialect.html#ogr-sql-dialect)

```
ogr2ogr -f GPKG mycities.gpkg worldcities.csv -oo X_POSSIBLE_NAMES=lng -oo Y_POSSIBLE_NAMES=lat -a_srs EPSG:4326 -sql "SELECT city, country, CAST(population AS integer) as population from worldcities where country = 'India'"
```

```
ogr2ogr -f GPKG mycities.gpkg worldcities.csv -oo X_POSSIBLE_NAMES=lng -oo Y_POSSIBLE_NAMES=lat -a_srs EPSG:4326 -sql "SELECT city, country, CAST(population AS integer) as population from worldcities where country = 'India'" -nln mycities
```

## Working with Multiple Layers

### Read Geonames Files

```
<OGRVRTDataSource>
	    <OGRVRTLayer name="CA">
	        <SrcDataSource>CSV:CA.txt</SrcDataSource>
	        <SrcLayer>CA</SrcLayer>
	    </OGRVRTLayer>
</OGRVRTDataSource>
```

```
ogrinfo -al -so CA.vrt
```

### Applying Filters

```
<OGRVRTDataSource>
	    <OGRVRTLayer name="CA">
	        <SrcDataSource>CSV:CA.txt</SrcDataSource>
	        <SrcLayer>CA</SrcLayer>
  	     	<SrcSQL>select * from CA where "FEATCLASS" = 'T'</SrcSQL>
	    </OGRVRTLayer>
</OGRVRTDataSource>
```

```
ogrinfo -al -so CA.vrt
```

### Merging Files

```

<OGRVRTDataSource>
	<OGRVRTUnionLayer name="NA">
	
	    <OGRVRTLayer name="CA">
	        <SrcDataSource>CSV:CA.txt</SrcDataSource>
	        <SrcLayer>CA</SrcLayer>
	     	<SrcSQL>select * from CA where "FEATCLASS" = 'T'</SrcSQL>
	    </OGRVRTLayer>
	
	    <OGRVRTLayer name="MX">
	        <SrcDataSource>CSV:MX.txt</SrcDataSource>
	        <SrcLayer>MX</SrcLayer>
	     	<SrcSQL>select * from MX where "FEATCLASS" = 'T'</SrcSQL>
	    </OGRVRTLayer>
	
	    <OGRVRTLayer name="US">
	        <SrcDataSource>CSV:US.txt</SrcDataSource>
	        <SrcLayer>US</SrcLayer>
	     	<SrcSQL>select * from US where "FEATCLASS" = 'T'</SrcSQL>
	    </OGRVRTLayer>
	
    </OGRVRTUnionLayer>	
</OGRVRTDataSource>
```


```
ogr2ogr -f GPKG NA.gpkg NA.vrt
```


## Geoprocessing and Spatial Queries

```
ogr2ogr -t_srs EPSG:7855 spatial_query.gpkg spatial_query.gpkg bars_and_pubs -update -nln bars_and_pubs_reprojected
ogr2ogr -t_srs EPSG:7855 spatial_query.gpkg spatial_query.gpkg metro_stations -update -nln metro_stations_reprojected
```

```
ogr2ogr spatial_query.gpkg spatial_query.gpkg -update -nln metro_stations_buffer -sql "select m.station, buffer(m.geom, 500) as geom from metro_stations_reprojected m" -dialect SQLITE 
```

You can dissolve the buffers using `ST_COLLECT`

```
ogr2ogr spatial_query.gpkg spatial_query.gpkg -update -nln metro_stations_buffer_dissolved -sql "select st_union(d.geom) as geom from (select st_collect(buffer(m.geom, 500)) as geom from metro_stations_reprojected m) as d" -dialect SQLITE
```

```
ogr2ogr -t_srs EPSG:4326 spatial_query.gpkg spatial_query.gpkg -update -nln selected -sql "select  b.* from bars_and_pubs_reprojected as b join metro_stations_buffer_dissolved as m on ST_Within( b.geom, m.geom)" -dialect SQLITE 
```

# Multi Criteria Weighted Overlay Analysis

Multi-criteria analysis is the process of the allocation of land to suit a specific
objective on the basis of a variety of attributes that the selected areas should possess.

Although this is a common GIS operation, it is best performed in the raster space. Below is the typical workflow to take source vector data, transform them to appropriate rasters, re-classify them and perform mathematical operations to do a suitability analysis.

We will work with crime and infrastructure data for the city of London and find suitable areas to build new parking facilities that can help reduce bicycle thefts. Our analysis will apply the following 3 criteria. The proposed parking must be

1. In a bicycle theft hotspot
2. Close to a bicycle route
3. Far from existing parking facilities

## Rasterize vector layers

For overlay analysis, all rasters must be of the same extent. So we first find the extent of the dataset that we can use while rasterizing.

```
ogrinfo multicriteria.gpkg
```

```
ogrinfo -so multicriteria.gpkg boundary
```

```
gdal_rasterize -burn 1 -add -tr 100 100 -te 523843.7 177847.3 531169.1 183893.8 multicriteria.gpkg -l bicycle_thefts thefts.tif -ot Int16
```

```
gdal_rasterize -ot Int16 -burn 1 -tr 10 10 -te 523843.7 177847.3 531169.1 183893.8 multicriteria.gpkg -l cycling_routes routes.tif

gdal_rasterize -ot Int16 -burn 1 -tr 10 10 -te 523843.7 177847.3 531169.1 183893.8 multicriteria.gpkg -l cycle_parking existing_parking.tif
```


## Generate proximity (Euclidean distance) rasters

```
gdal_proximity.py routes.tif outes_proximity.tif -ot Int16 -distunits GEO
gdal_proximity.py existing_parking.tif existing_parking_proximity.tif -ot Int16 -distunits GEO
```

## Re-classify raster values


|   **Thefts**  | **Routes**  | **Existing Parking** | Re-Class Value
|:--------------|:------------|:---------------------|---------------
| > 20          | 0-50m       | > 100m               | 100
| 10-20         | 50-100m     | 50-100m              | 50
| < 10          | > 100m      | < 50m                | 10

```
gdal_calc.py -A thefts.tif --outfile thefts_reclass.tif --calc="100*(A>20) + 50*(A>10)*(A<=20) + 10*(A<10)"

gdal_calc.py -A routes_proximity.tif --outfile routes_reclass.tif --calc="100*(A<=50) + 50*(A>50)*(A<=100) + 10*(A>100)"

gdal_calc.py -A existing_parking_proximity.tif --outfile existing_parking_reclass.tif --calc="100*(A>100) + 50*(A>50)*(A<=100) + 10*(A<50)"
```

## Overlay analysis

Roads and Water have a range of values, but protected areas are either 0 or 1. So we combine these together accordingly.

```
gdalwarp -r average -tr 100 100 existing_parking_reclass.tif parking_reclass_resampled.tif
gdalwarp -r average -tr 100 100 routes_reclass.tif routes_reclass_resampled.tif
```

```
gdal_calc.py -A thefts_reclass.tif -B routes_reclass_resampled.tif -C parking_reclass_resampled.tif --outfile suitability.tif --calc="(A + B + C)/3" --NoDataValue=0
```

# Running commands in batch

You can run the GDAL/OGR commands in a loop using Python. Say you want to convert the format of the images from JPEG200 to GeoTiff. You would run a command such as below.

```{bash eval=FALSE}
gdal_translate -of GTiff -co COMPRESS=JPEG {input} {output}
```

But it would be a lot of manual effort if you want to run the commands on hundreds of input files. Here's where a simple python script can help you automate running the commands in a batch. The data directory contains a file called `batch.py` with the following python code.

```{python eval=FALSE, code=readLines('code/gdal/batch.py')}
```

In OsGeo4W shell, run the following command to start batch processing on all tiles contained in the `naip/` directory.

```{bash eval=FALSE}
python3 batch.py
```

The data directory also contains an example of running the batch commands in parallel using python's built-in multiprocessing library. If your system has multi-core CPU, running commands in parallel like this on multiple threads can give you performance boost over running them in series.

```{python eval=FALSE, code=readLines('code/gdal/batch_parallel.py')}
```

The script runs the commands both in parallel and serial mode and prints the time taken by each of them.

```{bash eval=FALSE}
python3 batch-parallel.py
```

# Supplement

## Creating Colorized Hillshade

If you want to merge hillshade and color-relief to create a colored shaded relief map, you can use use `gdal_calc.py` to create do gamma and overlay calculations to combine the 2 rasters. [^1]

[^1]: Code reference https://gis.stackexchange.com/questions/255537/merging-hillshade-dem-data-into-color-relief-single-geotiff-with-qgis-and-gdal

```
gdal_calc.py -A hillshade.tif --outfile=gamma_hillshade.tif \
  --calc="uint8(((A / 255.)**(1/0.5)) * 255)"
```

```
gdal_calc.py -A gamma_hillshade.tif -B colorized.tif --allBands=B \
--calc="uint8( ( \
                 2 * (A/255.)*(B/255.)*(A<128) + \
                 ( 1 - 2 * (1-(A/255.))*(1-(B/255.)) ) * (A>=128) \
               ) * 255 )" --outfile=colorized_hillshade.tif
```               


```{r echo=FALSE, fig.align='center', out.width='75%', fig.cap='Colorized Shaded Relief'}
knitr::include_graphics('images/gdal/colorized_hillshade.png')
```


# Resources
* [GDAL Tips](https://twitter.com/gdaltips) `@gdaltips` on Twitter

# Data Credits

* OpenStreetMap (osm) data layers: Data/Maps Copyright 2019 Geofabrik GmbH and OpenStreetMap Contributors. [OSM India free extract](https://download.geofabrik.de/asia/india.html) downloaded from Geofabrik.
* Landsat: Landsat-8 image courtesy of the U.S. Geological Survey. Image downloaded from [Google Cloud Platform](https://console.cloud.google.com/marketplace/details/usgs-public-data/landast) and pre-processed using [Semi Automatic Classification Plugin from QGIS](https://fromgistors.blogspot.com/p/semi-automatic-classification-plugin.html)
* Earth at Night image: Credit: NASA Earth Observatory/NOAA NGDC. Earth at Night flat hi-resolution map downloaded from [NASA earth observatory](https://earthobservatory.nasa.gov/features/NightLights/page3.php)
* William Mackenzie 1870 map of Southern India:  out-of-copyright scanned map downloaded from [Hipkiss’s Scanned Old Maps](http://www.hipkiss.org/data/maps.html)
* NAIP 2016 Aerial Imagery for California: The National Agriculture Imagery Program (NAIP). USDA-FSA-APFO Aerial Photography Field Office. Downloaded from [NRCS](https://nrcs.app.box.com/v/naip/folder/18144379349)

# License

This course material is licensed under a [Creative Commons Attribution-NonCommercial 4.0 International License](https://creativecommons.org/licenses/by-nc/4.0/). You are free to use the material for any non-commercial purpose. Kindly give appropriate credit to the original author.

&copy; 2020 Ujaval Gandhi [www.spatialthoughts.com](http://spatialthoughts.com)

***

**This course is offered as an instructor-led online class. Visit [Spatial Thoughts](https://spatialthoughts.com/events/) to know details of upcoming sessions.**
