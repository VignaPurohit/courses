{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCi5DKHB7jag"
   },
   "source": [
    "[XEE](https://github.com/google/Xee) is an python package for working with Google Earth Engine data with [XArray](https://docs.xarray.dev/en/stable/). XEE makes it possible to leverage the strengths of both GEE and the Python ecosystem around XArray.\n",
    "\n",
    "We will learn how to use XEE to extract and process a NDVI time-series for a single point location.\n",
    "\n",
    "If you want to download processed time-series images as GeoTIFF files, pleasee see [this notebook](https://courses.spatialthoughts.com/python-remote-sensing.html#processing-time-series)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YauILMlxtHa_"
   },
   "source": [
    "#### Installation\n",
    "\n",
    "Let's install the required packages in the Colab environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aQpTzbC0l73O"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    !pip install --upgrade xee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NaQVEndwjA-K"
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "import xarray\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CpVwpjkjIAJQ"
   },
   "source": [
    "#### Initialization\n",
    "\n",
    "First of all, you need to run the following cells to initialize the API and authorize your account. You must have a Google Cloud Project associated with your GEE account. Replace the `cloud_project` with your own project from [Google Cloud Console](https://console.cloud.google.com/).\n",
    "\n",
    "We are using the [High-volume Endpoint](https://developers.google.com/earth-engine/cloud/highvolume) which supports large number of concurrent requests and is recommended when working with XEE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gjRJhBKF2iLf"
   },
   "outputs": [],
   "source": [
    "cloud_project = 'spatialthoughts'\n",
    "\n",
    "try:\n",
    "    ee.Initialize(\n",
    "        project=cloud_project,\n",
    "        opt_url='https://earthengine-highvolume.googleapis.com'\n",
    "    )\n",
    "except:\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize(\n",
    "        project=cloud_project,\n",
    "        opt_url='https://earthengine-highvolume.googleapis.com'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1VjIDABXv9D"
   },
   "source": [
    "#### Select a location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SqWOJq_AX2hZ"
   },
   "outputs": [],
   "source": [
    "geometry = ee.Geometry.Point([82.60759592318209, 27.163481733946846])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILQivF-WHU4i"
   },
   "source": [
    "#### Preprocess the data in GEE\n",
    "\n",
    "We start with the Sentinel-2 L1C collection. We pre-process the data by applying cloud masking and pixel scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pvk0YiD5Xx4x"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oj0K-RbvHL17"
   },
   "outputs": [],
   "source": [
    "s2 = ee.ImageCollection('COPERNICUS/S2_HARMONIZED')\n",
    "\n",
    "filtered = s2 \\\n",
    "  .filter(ee.Filter.date('2017-01-01', '2018-01-01')) \\\n",
    "  .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)) \\\n",
    "  .filter(ee.Filter.bounds(geometry))\n",
    "\n",
    "# Load the Cloud Score+ collection\n",
    "csPlus = ee.ImageCollection('GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED')\n",
    "csPlusBands = csPlus.first().bandNames()\n",
    "\n",
    "# We need to add Cloud Score + bands to each Sentinel-2\n",
    "# image in the collection\n",
    "# This is done using the linkCollection() function\n",
    "filteredS2WithCs = filtered.linkCollection(csPlus, csPlusBands)\n",
    "\n",
    "# Function to mask pixels with low CS+ QA scores.\n",
    "def maskLowQA(image):\n",
    "  qaBand = 'cs'\n",
    "  clearThreshold = 0.5\n",
    "  mask = image.select(qaBand).gte(clearThreshold)\n",
    "  return image.updateMask(mask)\n",
    "\n",
    "filteredMasked = filteredS2WithCs \\\n",
    "  .map(maskLowQA)\n",
    "\n",
    "# Write a function that computes NDVI for an image and adds it as a band\n",
    "# Create a new image to overcome https://github.com/google/Xee/issues/88\n",
    "def addNDVI(image):\n",
    "  ndvi = image.normalizedDifference(['B8', 'B4']).rename('ndvi')\n",
    "  return image.multiply(0.0001).addBands(ndvi)\\\n",
    "    .copyProperties(image, ['system:time_start'])\n",
    "\n",
    "# Map the function over the collection\n",
    "withNdvi = filteredMasked.map(addNDVI)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJpnLft8Hvj-"
   },
   "source": [
    "#### Load ImageCollection as XArray Dataset\n",
    "\n",
    "Now we have an ImageCollection that we want to get it as a XArray Dataset. We define the region of interest and extract the ImageCollection using the `ee` engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UgJ1f8IOH7hM"
   },
   "outputs": [],
   "source": [
    "ds = xarray.open_dataset(\n",
    "    withNdvi,\n",
    "    engine='ee',\n",
    "    crs='EPSG:3857',\n",
    "    scale=10,\n",
    "    geometry=geometry,\n",
    "    ee_mask_value=-9999,\n",
    ")\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOkAc80VKthU"
   },
   "source": [
    "Select the `ndvi` band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U_D_VlVMKwGc"
   },
   "outputs": [],
   "source": [
    "ndvi_time_series = ds.ndvi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6YbbjVgrK54D"
   },
   "source": [
    "Run `compute()` to fetch the pixels from Earth Engine. This may take some time depending on the size of the request. This is a time-series at a single pixel, so we also `squeeze()` to remove the X and Y dimensions and get an array of NDVI values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EHRySbYfKz2z"
   },
   "outputs": [],
   "source": [
    "original_time_series = ndvi_time_series.compute()\n",
    "original_time_series = original_time_series.squeeze()\n",
    "original_time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJOU4JJ9WDZM"
   },
   "source": [
    "Plot the time-series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LtzSOp91LEaU"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(10, 5)\n",
    "original_time_series.plot.line(\n",
    "    ax=ax, x='time',\n",
    "    marker='o', color='#66c2a4', linestyle='--', linewidth=1, markersize=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mr5sf4dOLGP"
   },
   "source": [
    "#### Process Time-Series using XArray\n",
    "\n",
    "We use XArray's excellent time-series processing functionality to process the time-series. First, we create a regularly spaced time-series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yI-hDl-WNG02"
   },
   "outputs": [],
   "source": [
    "time_series_resampled = original_time_series\\\n",
    "  .resample(time='5d').mean(dim='time')\n",
    "time_series_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_p1BtZeVpC6"
   },
   "source": [
    "Next we fill the cloud-masked pixels with linearly interpolated values from temporal neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A8r66xrNQE5z"
   },
   "outputs": [],
   "source": [
    "time_series_interpolated = time_series_resampled\\\n",
    "  .interpolate_na('time', use_coordinate=False)\n",
    "time_series_interpolated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-MxhCHExVxSA"
   },
   "source": [
    "We also apply a moving-window smoothing to remove noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wUHBPZMwSZ4w"
   },
   "outputs": [],
   "source": [
    "time_series_smooth = time_series_interpolated\\\n",
    "  .rolling(time=3, center=True).mean()\n",
    "time_series_smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7GX6VvGV0Gp"
   },
   "source": [
    "A moving-window smoothing removed the first and last values of the time-series. We anchor the smoothed time-series with the values from the original time-series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HZi7SAYOTK0R"
   },
   "outputs": [],
   "source": [
    "time_series_smooth[0] = original_time_series[0]\n",
    "time_series_smooth[-1] = original_time_series[-1]\n",
    "time_series_smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdOgykrmWAJR"
   },
   "source": [
    "Plot the original and smoothed time-series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9h1R2aPfOgNd"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "fig.set_size_inches(10, 5)\n",
    "original_time_series.plot.line(\n",
    "    ax=ax, x='time',\n",
    "    marker='^', color='#66c2a4', linestyle='--', linewidth=1, markersize=2)\n",
    "time_series_smooth.plot.line(\n",
    "    ax=ax, x='time',\n",
    "    marker='o', color='#238b45', linestyle='-', linewidth=1, markersize=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8didZQcyWJ06"
   },
   "source": [
    "#### Download the Time-Series\n",
    "\n",
    "Convert the DataArray to a Pandas DataFrame and save it as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xt6gahlZPpB8"
   },
   "outputs": [],
   "source": [
    "df = time_series_smooth.to_dataframe('ndvi').reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UKlr1x5xWUMm"
   },
   "outputs": [],
   "source": [
    "output_filename = 'smoothed_time_series.csv'\n",
    "df[['time', 'ndvi']].to_csv(output_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DFfLX-QhYM58"
   },
   "source": [
    "### Exercise\n",
    "\n",
    "Replace the `geometry` with the location of your choice. Extract and download the smoothed time-series as a CSV file."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
